{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING DATA\n",
    "import pandas as pd #need panda first of course\n",
    "\n",
    "df_train = pd.read_csv(\"~/Documents/train.csv\")\n",
    "df_test = pd.read_csv(\"~/Documents/test.csv\")\n",
    "\n",
    "df_train = pd.read_csv(r\"D:/namafolder/train.csv\")\n",
    "df_test = pd.read_csv(r\"D:/namafolder/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine or Split 2 Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINE\n",
    "ntrain = df_train.shape[0]\n",
    "ntest = df_test.shape[0]\n",
    "\n",
    "all_data = pd.concat((df_train, df_test)).reset_index(drop=True)\n",
    "\n",
    "nindex, nfeatures = all_data.shape\n",
    "\n",
    "# SPLIT\n",
    "X_train =  all_data[:-ntest].drop(['SalePrice'], axis=1)\n",
    "y_train =  all_data[:-ntest]['SalePrice']\n",
    "X_test  =  all_data[-ntest:].drop(['SalePrice'], axis=1)\n",
    "\n",
    "# SPLIT\n",
    "df_train_final = all_data.iloc[:1460]\n",
    "df_test_final = all_data.iloc[1460:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "idsUnique = len(set(df_train.Id))\n",
    "idsTotal = df_train.shape[0]\n",
    "idsDupli = idsTotal - idsUnique\n",
    "print(\"There are \" + str(idsDupli) + \" duplicate IDs for \" + str(idsTotal) + \" total entries\")\n",
    "\n",
    "# Drop Id column\n",
    "#df_train.drop(\"Id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the dataframe with all the features and SUM of the NaN values present\n",
    "df_null_count = dataframe.isnull().sum().to_frame().rename({0:\"Sum\"}, axis=1)\n",
    "\n",
    "## Select only those features who have atleast 1 NaN value\n",
    "df_null_count = df_null_count[df_null_count['Sum'] > 0]\n",
    "\n",
    "## Change the SUM to PERCENTAGE \n",
    "df_null_count['Sum'] = df_null_count['Sum']*(100/nindex)\n",
    "\n",
    "## Plot a Horizontal Bar Graph\n",
    "df_null_count.sort_values(by=\"Sum\", ascending=True).plot(\n",
    "    kind='barh', figsize=(12,10), fontsize=14, colormap=\"RdBu_r\", title=\"Percentage wise null values\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Total number of entries with Null\n",
    "print(f\"Total number of entries with Null Feature Type are {len(dataframe.index)}.\")\n",
    "\n",
    "# drop feature\n",
    "dataframe.drop(['Feature1'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle remaining missing values for numerical features by using median as replacement\n",
    "print(\"NAs for numerical features in train : \" + str(train_num.isnull().values.sum()))\n",
    "train_num = train_num.fillna(train_num.median())\n",
    "print(\"Remaining NAs for numerical features in train : \" + str(train_num.isnull().values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace null with none values in feature\n",
    "#catogorical\n",
    "for feature in ['feature1', 'feature2', 'feature3', 'feature4']:\n",
    "    dataframe[feature].fillna(value='None', inplace=True)\n",
    "    \n",
    "#numeric\n",
    "for feature in ['feature1', 'feature2', 'feature3']:\n",
    "    all_data[feature].fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mode Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mode Imputation\n",
    "mode_val = all_data.MasVnrType.value_counts().idxmax()    # 'None'\n",
    "all_data['feature1'].fillna(mode_val, inplace=True) \n",
    "\n",
    "train_df['feature1'] = train_df['feature1'].fillna(train_df['feature1'].mode()[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Median Imputation\n",
    "median_val = all_data.MasVnrArea.median()     # 0\n",
    "all_data['feature1'].fillna(median_val, inplace=True)\n",
    "\n",
    "#Median Imputation\n",
    "dataframe['feature'].fillna(value=dataframe['feature'].median(), inplace=True)\n",
    "-----\n",
    "dataframe['feature1'] = dataframe['feature1'].fillna(dataframe['feature1'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
